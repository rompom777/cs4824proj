# Interpretable Bird Classification Using Concept Bottleneck Models  
### Final Project â€” Machine Learning  
**Authors:** Roman Zrajevsky, Benjamin Clements  

---

## ğŸ¦ Overview

This repository contains our full implementation of a **Concept Bottleneck Model (CBM)** for interpretable fine-grained bird species classification using the **CUB-200-2011 dataset**.

Standard CNNs achieve high accuracy but operate as *black boxes*. CBMs introduce a middle layer of **human-interpretable concepts** (e.g., wing color, bill shape, breast pattern) that the model must predict before classifying species.

This repository includes:

- Baseline ResNet-18 classifier (**x â†’ y**)
- Concept predictor (**x â†’ Ä‰**)
- Label-from-concepts classifier (**Ä‰ â†’ y**)
- Full CBM pipeline (**x â†’ Ä‰ â†’ y**)
- Concept explanations and manual interventions
- Complete preprocessing pipeline for CUB
- Training + evaluation scripts for all components

---

# ğŸ“ Repository Structure
project-root/
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ cub_raw/ # Place downloaded dataset here
â”‚ â”œâ”€â”€ cub_csvs/ # Output of preprocessing - created by the program
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ prepare_cub.py # Dataset preprocessing pipeline
â”‚ â”œâ”€â”€ baseline.py # Baseline ResNet-18 (x â†’ y)
â”‚ â”œâ”€â”€ concept_predictor.py # Concept model (x â†’ Ä‰)
â”‚ â”œâ”€â”€ c2y_classifier.py # Label-from-concepts classifier (Ä‰ â†’ y)
â”‚ â”œâ”€â”€ cbm_pipeline.py # Full CBM evaluation
â”‚ â”œâ”€â”€ train_utils.py # Shared training utilities
â”‚ â”œâ”€â”€ evaluate.py # Evaluation scripts
â”‚ â”œâ”€â”€ explain.py # Concept explanations & interventions
â”‚
â”œâ”€â”€ checkpoints/ # Saved model weights
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

# âš™ï¸ Installation

## 1. Clone the Repository
```bash
git clone https://github.com/<your-username>/<repo-name>.git
cd <repo-name>
```

## 2. Create Virtual Environment
python3 -m venv venv
source venv/bin/activate      # Mac / Linux
venv\Scripts\activate         # Windows

## 3. Install Dependencies
pip install -r requirements.txt


Key libraries:
PyTorch & Torchvision
NumPy / Pandas
scikit-learn
Matplotlib
tqdm
Pillow

ğŸ“¥ Downloading the Dataset

The dataset is not included because it is too large for GitHub.

Download CUB-200-2011:

Official page:
http://www.vision.caltech.edu/datasets/cub_200_2011/

Place it here:
data/cub_raw/CUB_200_2011/

ğŸ§¹ Preprocessing the Dataset
Run this to generate clean CSVs and concept matrices:
python src/prepare_cub.py \
    --cub_root data/cub_raw/CUB_200_2011 \
    --output_dir data/cub_processed

This script:
Parses metadata
Extracts 312 concept attributes
Builds train/val/test splits
Produces numpy matrices for fast training

ğŸ‹ï¸ Training the Models
You may train components individually or the entire CBM pipeline.
ğŸ”µ 1. Train the Baseline ResNet-18 (x â†’ y)
python src/baseline.py \
    --data_dir data/cub_processed \
    --epochs 10 \
    --batch_size 32 \
    --lr 0.001 \
    --save_path checkpoints/baseline_best.pt

ğŸŸ¢ 2. Train the Concept Predictor (x â†’ Ä‰)
python src/concept_predictor.py \
    --data_dir data/cub_processed \
    --epochs 20 \
    --batch_size 32 \
    --lr 0.001 \
    --save_path checkpoints/concept_predictor_best.pt

ğŸŸ¡ 3. Train the Label-From-Concepts Classifier (Ä‰ â†’ y)
Using ground truth concepts (â€œoracle CBMâ€):
python src/c2y_classifier.py \
    --concept_dir data/cub_processed \
    --epochs 15 \
    --lr 0.001 \
    --save_path checkpoints/label_from_concepts_best.pt

ğŸ”´ 4. Evaluate the Full CBM Pipeline (x â†’ Ä‰ â†’ y)
python src/cbm_pipeline.py \
    --concept_model checkpoints/concept_predictor_best.pt \
    --classifier checkpoints/label_from_concepts_best.pt \
    --data_dir data/cub_processed \
    --evaluate

ğŸ“Š Evaluation
Evaluate any model:
python src/evaluate.py --model_type baseline --checkpoint checkpoints/baseline_best.pt
python src/evaluate.py --model_type concept --checkpoint checkpoints/concept_predictor_best.pt
python src/evaluate.py --model_type c2y --checkpoint checkpoints/label_from_concepts_best.pt
python src/evaluate.py --model_type cbm --config configs/cbm.yaml

ğŸ“ Notes for Graders
Dataset not included due to size limits
All scripts fully reproducible from raw data
Preprocessing must be run before training
Checkpoints included for convenience
Explanation engine demonstrates interpretability criteria
